# Introduction

The way in which human beings express their emotions
has always been a topic of interest in psychological study.
External factors have always proven to play a major role
as different groups of people show different reaction to the
same stimuli, and the way of their emotional expression sets
them apart from any other group of interest. The common
factors in this change of expressions are observed as gender,
cultural influences, age, and the environment. Expression of
the commonly observed emotions such as *happiness*, *fear*,
*disgust*, and *sadness* is specific to the individuals, based
on their personality traits. The expressions of an introvert
would be different from that of an extrovert when subjected
to the same stimuli, and having same emotional changes.

> In this problem, our main focus is the facial expression recognition, as the reaction to a stimulus is first observed through face. 

As cultural factors influence the display of
emotions, and we are dealing with the Indo-Pak ethnicity,we show how an ethnicity-specific classifier is built using
the target domain data that is unlabeled. The assumptions
made by our proposed method will not be based on specific features used for emotional representation, so the proposed solution can be applied to a different kind of data also.
We propose to use Cycle-GAN for the purpose of mapping
source domain to target domain, and conduct the comparative analysis with results of conventional GAN model.

# Related Work

There were two commonly used techniques in the observed literature to achieve the similar results related to
the problem being addressed. First is a state-of-the-art approach based on a frame-level technique, which is the facial
expression analysis using single frame. For this approach,
the pre-requisite is to perform image registration on facial
images, and then drawing out the representative features of
the image i.e. geometrical features. These extracted features are then given as an input to the classifier. This method
is observed to show good results concerning frontal images,
but it failed to capture the diversity of emotions.
Second most commonly seen approach is of domain
adaptation, along with other transfer learning techniques
which depend on the type of information. These techniques
include feature and parameter transfer. Former technique
deals with the shared feature space representing both target
domain and source domain, whereas the latter deals with
finding the shared parameters between both domains.
In cases where the data representing the target domain is
unlabeled, instance-based domain adaptation techniques are
used. This is made possible through the observation of target domain’s distribution. Using the information extracted
from the distribution, certain weight is assigned to the samples of source domain while training, and certain samples
are estimated. In [3], an Identity-free conditional Generative Adversarial Network was proposed, known as IF-GAN. It was introduced for the purpose of reducing variations among the subjects for recognition of facial expression. A neutral face can
be transformed to an expressive one using conditional generation, for a given input image. The neutral face subjected
to transformation here is artificially generated by the model,
which is trained on the neutral expressions of other subjects.
The generated neutral face is then transformed to imitate
the same expression as the input image. Since the transformed images have the same synthetic ”average” identity,
they differ from each other by only their expressions and
thus, can be used for identity-free expression classification.
In this work, an end-to-end system was developed to perform expression transformation and expression recognition
in the IF-GAN framework. Experimental results on three
facial expression datasets have demonstrated that the proposed IF-GAN outperforms the baseline CNN model and
achieves comparable or better performance compared with
the state-of-the-art methods for facial expression recognition.

# Base Papers

Three base papers were concerned before finalizing the
approach proposed by us. [4] introduces an unsupervised
domain adaptation method, which is especially suitable for
unlabeled small target dataset. They train a GAN on the
target dataset and use the GAN generated samples to finetune the model pretrained on the source dataset, whereas
[2] proposes an domain adaptation approach that promotes
the emergence of features that are (i) discriminative for the
main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. On
the other hand, in [1] the authors present an approach that
learns, in an unsupervised manner, a transformation in the
pixel space from one domain to the other. Their GAN-based
method adapts source-domain images to appear as if drawn
from the target domain.

# Dataset

We have source domain and target domain for source domain we used publicly available FER-2013 and CK+ datasets and for target domcin we collected dataset of 3K+ images. The sample images were resized to 224x224, as required by implemented model for training purposes.

![Branching](https://raw.githubusercontent.com/adaptivefer/adaptivefer.github.io/master/assets/images/download%20(1).png)

# Implimentation

We are using Input Space Domain Adaptation to address our problem. In our experiments we generated target
domain like samples from CycleGAN and fine-tuned our
model on it and source data. We used two classifeirs, VGG16 and ResNET18, for this purpose. Our accuracy is less
than what was expected. We are working on an unsupervised technique for domain adaptation as proposed in [4].
The WGAN used in it is not yet producing promising results so we didn’t include its results in the report.

# Conclusion

We are using Input Space Domain Adaptation to address our problem. In our experiments we generated target
domain like samples from CycleGAN and fine-tuned our
model on it and source data. We used two classifeirs, VGG16 and ResNET18, for this purpose. Our accuracy is less
than what was expected. We are working on an unsupervised technique for domain adaptation as proposed in [4].
The WGAN used in it is not yet producing promising results so we didn’t include its results in the report.
